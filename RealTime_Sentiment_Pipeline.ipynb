{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Real-Time Stock Data & Sentiment Analysis Pipeline\n",
    "\n",
    "This notebook implements a real-time pipeline that:\n",
    "1.  Ingests stock price data via Finnhub WebSocket.\n",
    "2.  Ingests/Simulates news and social media text.\n",
    "3.  Analyzes sentiment using FinBERT and VADER.\n",
    "4.  Aggregates features in real-time.\n",
    "5.  Prepares data for model inference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install dependencies if not already installed\n",
    "!pip install websocket-client transformers vaderSentiment yfinance torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import websocket\n",
    "import json\n",
    "import threading\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import yfinance as yf\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, pipeline\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "import queue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- CONFIGURATION ---\n",
    "API_KEY = \"YOUR_FINNHUB_KEY\"  # <--- REPLACE THIS WITH YOUR KEY\n",
    "SYMBOL = \"AAPL\"\n",
    "FINBERT_MODEL = \"ProsusAI/finbert\"\n",
    "\n",
    "# Global buffers for real-time data\n",
    "price_buffer = queue.Queue()\n",
    "news_buffer = queue.Queue()\n",
    "social_buffer = queue.Queue()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Price Ingestion (WebSocket)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def on_message(ws, message):\n",
    "    try:\n",
    "        data = json.loads(message)\n",
    "        if data.get('type') == 'trade':\n",
    "            for trade in data['data']:\n",
    "                # Extract price (p) and timestamp (t)\n",
    "                record = {\n",
    "                    'symbol': trade['s'],\n",
    "                    'price': trade['p'],\n",
    "                    'timestamp': trade['t'] / 1000.0,  # Convert ms to seconds\n",
    "                    'volume': trade['v']\n",
    "                }\n",
    "                price_buffer.put(record)\n",
    "                # print(f\"Trade: {record}\") # Debug print\n",
    "    except Exception as e:\n",
    "        print(f\"Error parsing message: {e}\")\n",
    "\n",
    "def on_error(ws, error):\n",
    "    print(f\"WebSocket Error: {error}\")\n",
    "\n",
    "def on_close(ws, close_status_code, close_msg):\n",
    "    print(\"WebSocket Closed\")\n",
    "\n",
    "def on_open(ws):\n",
    "    print(f\"Subscribing to {SYMBOL}...\")\n",
    "    ws.send(json.dumps({\"type\": \"subscribe\", \"symbol\": SYMBOL}))\n",
    "\n",
    "def start_finnhub_ws():\n",
    "    if API_KEY == \"YOUR_FINNHUB_KEY\":\n",
    "        print(\"WARNING: No API Key provided. WebSocket will not connect.\")\n",
    "        return\n",
    "    \n",
    "    websocket.enableTrace(False)\n",
    "    url = f\"wss://ws.finnhub.io?token={API_KEY}\"\n",
    "    ws = websocket.WebSocketApp(url,\n",
    "                                on_open=on_open,\n",
    "                                on_message=on_message,\n",
    "                                on_error=on_error,\n",
    "                                on_close=on_close)\n",
    "    ws.run_forever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start WebSocket in a background thread\n",
    "ws_thread = threading.Thread(target=start_finnhub_ws, daemon=True)\n",
    "ws_thread.start()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Alternative: Polling with yfinance (for testing without API key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def poll_yfinance():\n",
    "    # Simulate real-time by fetching latest minute bar\n",
    "    try:\n",
    "        df = yf.download(SYMBOL, period=\"1d\", interval=\"1m\", progress=False)\n",
    "        if not df.empty:\n",
    "            latest = df.iloc[-1]\n",
    "            record = {\n",
    "                'symbol': SYMBOL,\n",
    "                'price': float(latest['Close']),\n",
    "                'timestamp': time.time(), # Approximate current time\n",
    "                'volume': int(latest['Volume'])\n",
    "            }\n",
    "            price_buffer.put(record)\n",
    "            # print(f\"Polled: {record}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Polling error: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Sentiment Analysis Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- FinBERT Setup ---\n",
    "print(\"Loading FinBERT...\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(FINBERT_MODEL)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(FINBERT_MODEL)\n",
    "finbert_pipeline = pipeline(\"sentiment-analysis\", model=model, tokenizer=tokenizer)\n",
    "print(\"FinBERT Loaded.\")\n",
    "\n",
    "# --- VADER Setup ---\n",
    "vader_analyzer = SentimentIntensityAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_news(text):\n",
    "    \"\"\"Returns FinBERT score: {'label': 'positive'/'negative'/'neutral', 'score': float}\"\"\"\n",
    "    try:\n",
    "        result = finbert_pipeline(text)[0]\n",
    "        # Map to numeric score? Or keep as label/confidence\n",
    "        # Simple mapping: positive=1, neutral=0, negative=-1 * score\n",
    "        val = 0\n",
    "        if result['label'] == 'positive':\n",
    "            val = result['score']\n",
    "        elif result['label'] == 'negative':\n",
    "            val = -result['score']\n",
    "        return val\n",
    "    except Exception as e:\n",
    "        print(f\"FinBERT error: {e}\")\n",
    "        return 0.0\n",
    "\n",
    "def score_social(text):\n",
    "    \"\"\"Returns VADER compound score\"\"\"\n",
    "    return vader_analyzer.polarity_scores(text)['compound']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Feature Aggregation Logic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aggregate_features(price_list, news_list, social_list):\n",
    "    \"\"\"\n",
    "    Aggregates raw data buffers into a single feature vector.\n",
    "    This is a simplified example aggregating over the collected batch.\n",
    "    \"\"\"\n",
    "    features = {}\n",
    "    \n",
    "    # Price Features\n",
    "    if price_list:\n",
    "        df_p = pd.DataFrame(price_list)\n",
    "        features['price_mean'] = df_p['price'].mean()\n",
    "        features['price_std'] = df_p['price'].std()\n",
    "        features['price_last'] = df_p['price'].iloc[-1]\n",
    "        features['volume_sum'] = df_p['volume'].sum()\n",
    "    else:\n",
    "        features['price_mean'] = np.nan\n",
    "        features['price_last'] = np.nan\n",
    "    \n",
    "    # News Sentiment\n",
    "    if news_list:\n",
    "        scores = [score_news(n['text']) for n in news_list]\n",
    "        features['news_sent_mean'] = np.mean(scores)\n",
    "        features['news_count'] = len(scores)\n",
    "    else:\n",
    "        features['news_sent_mean'] = 0\n",
    "        features['news_count'] = 0\n",
    "        \n",
    "    # Social Sentiment\n",
    "    if social_list:\n",
    "        scores = [score_social(s['text']) for s in social_list]\n",
    "        features['social_sent_mean'] = np.mean(scores)\n",
    "        features['social_count'] = len(scores)\n",
    "    else:\n",
    "        features['social_sent_mean'] = 0\n",
    "        features['social_count'] = 0\n",
    "        \n",
    "    return features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Main Real-Time Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dummy data generator for testing sentiment pipeline\n",
    "def generate_dummy_text():\n",
    "    import random\n",
    "    news_headlines = [\n",
    "        \"Apple reports record quarterly revenue.\",\n",
    "        \"Tech sector faces headwinds from new regulations.\",\n",
    "        \"Analysts upgrade AAPL price target.\",\n",
    "        \"Supply chain issues persist for major tech companies.\"\n",
    "    ]\n",
    "    tweets = [\n",
    "        \"Buying the dip! $AAPL to the moon!\",\n",
    "        \"Market looks weak today, selling my positions.\",\n",
    "        \"Just bought a new iPhone, love it.\",\n",
    "        \"Why is the stock dropping??\"\n",
    "    ]\n",
    "    \n",
    "    if random.random() < 0.3:\n",
    "        news_buffer.put({'text': random.choice(news_headlines), 'timestamp': time.time()})\n",
    "    if random.random() < 0.5:\n",
    "        social_buffer.put({'text': random.choice(tweets), 'timestamp': time.time()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Starting Real-Time Pipeline Loop... (Stop manually to exit)\")\n",
    "\n",
    "try:\n",
    "    while True:\n",
    "        # 1. Ingest Data\n",
    "        # (WebSocket is filling price_buffer in background)\n",
    "        # If no API key, use polling:\n",
    "        if API_KEY == \"YOUR_FINNHUB_KEY\":\n",
    "            poll_yfinance()\n",
    "            \n",
    "        # Generate dummy text for demo purposes\n",
    "        generate_dummy_text()\n",
    "        \n",
    "        # 2. Drain Buffers (Process collected data for this window)\n",
    "        current_prices = []\n",
    "        while not price_buffer.empty():\n",
    "            current_prices.append(price_buffer.get())\n",
    "            \n",
    "        current_news = []\n",
    "        while not news_buffer.empty():\n",
    "            current_news.append(news_buffer.get())\n",
    "            \n",
    "        current_social = []\n",
    "        while not social_buffer.empty():\n",
    "            current_social.append(social_buffer.get())\n",
    "            \n",
    "        # 3. Aggregate & Analyze\n",
    "        if current_prices or current_news or current_social:\n",
    "            feats = aggregate_features(current_prices, current_news, current_social)\n",
    "            feats['timestamp'] = datetime.now().strftime(\"%H:%M:%S\")\n",
    "            \n",
    "            # 4. Output / Inference\n",
    "            print(f\"[{feats['timestamp']}] Price: {feats['price_last']:.2f} | News Sent: {feats['news_sent_mean']:.2f} ({feats['news_count']}) | Social Sent: {feats['social_sent_mean']:.2f} ({feats['social_count']})\")\n",
    "            \n",
    "            # Here you would feed `feats` into your ML model:\n",
    "            # prediction = model.predict(feats)\n",
    "            \n",
    "        time.sleep(5) # Run loop every 5 seconds for demo\n",
    "        \n",
    "except KeyboardInterrupt:\n",
    "    print(\"Pipeline stopped.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
